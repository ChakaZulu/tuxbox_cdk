diff --git a/Makefile b/Makefile
index 497884d..30a99e3 100644
--- a/Makefile
+++ b/Makefile
@@ -1,7 +1,7 @@
 VERSION = 2
 PATCHLEVEL = 6
 SUBLEVEL = 15
-EXTRAVERSION =
+EXTRAVERSION = -dbox2
 NAME=Sliding Snow Leopard
 
 # *DOCUMENTATION*
diff --git a/arch/ppc/8xx_io/enet.c b/arch/ppc/8xx_io/enet.c
index ece6a9f..f05207d 100644
--- a/arch/ppc/8xx_io/enet.c
+++ b/arch/ppc/8xx_io/enet.c
@@ -14,13 +14,6 @@
  * Buffer descriptors are kept in the CPM dual port RAM, and the frame
  * buffers are in the host memory.
  *
- * Right now, I am very watseful with the buffers.  I allocate memory
- * pages and then divide them into 2K frame buffers.  This way I know I
- * have buffers large enough to hold one frame within one buffer descriptor.
- * Once I get this working, I will use 64 or 128 byte CPM buffers, which
- * will be much more memory efficient and will easily handle lots of
- * small packets.
- *
  */
 #include <linux/config.h>
 #include <linux/kernel.h>
@@ -56,11 +49,7 @@
  *
  * The buffer descriptors are allocated from the CPM dual port memory
  * with the data buffers allocated from host memory, just like all other
- * serial communication protocols.  The host memory buffers are allocated
- * from the free page pool, and then divided into smaller receive and
- * transmit buffers.  The size of the buffers should be a power of two,
- * since that nicely divides the page.  This creates a ring buffer
- * structure similar to the LANCE and other controllers.
+ * serial communication protocols.
  *
  * Like the LANCE driver:
  * The driver runs as two independent, single-threaded flows of control.  One
@@ -92,20 +81,14 @@
  * pool.  The code may assume these are power of two, so it is best
  * to keep them that size.
  * We don't need to allocate pages for the transmitter.  We just use
- * the skbuffer directly.
+ * the skbuffer directly. Receiving data works by swapping skbuffers.
  */
 #ifdef CONFIG_ENET_BIG_BUFFERS
-#define CPM_ENET_RX_PAGES	32
-#define CPM_ENET_RX_FRSIZE	2048
-#define CPM_ENET_RX_FRPPG	(PAGE_SIZE / CPM_ENET_RX_FRSIZE)
-#define RX_RING_SIZE		(CPM_ENET_RX_FRPPG * CPM_ENET_RX_PAGES)
+#define RX_RING_SIZE		64
 #define TX_RING_SIZE		64	/* Must be power of two */
 #define TX_RING_MOD_MASK	63	/*   for this to work */
 #else
-#define CPM_ENET_RX_PAGES	4
-#define CPM_ENET_RX_FRSIZE	2048
-#define CPM_ENET_RX_FRPPG	(PAGE_SIZE / CPM_ENET_RX_FRSIZE)
-#define RX_RING_SIZE		(CPM_ENET_RX_FRPPG * CPM_ENET_RX_PAGES)
+#define RX_RING_SIZE		8
 #define TX_RING_SIZE		8	/* Must be power of two */
 #define TX_RING_MOD_MASK	7	/*   for this to work */
 #endif
@@ -129,6 +112,8 @@ struct scc_enet_private {
 	struct	sk_buff* tx_skbuff[TX_RING_SIZE];
 	ushort	skb_cur;
 	ushort	skb_dirty;
+	struct	sk_buff* rx_skbuff[RX_RING_SIZE];
+	ushort	skb_cur_rx;
 
 	/* CPM dual port RAM relative addresses.
 	*/
@@ -141,7 +126,6 @@ struct scc_enet_private {
 	/* Virtual addresses for the receive buffers because we can't
 	 * do a __va() on them anymore.
 	 */
-	unsigned char *rx_vaddr[RX_RING_SIZE];
 	struct	net_device_stats stats;
 	uint	tx_full;
 	spinlock_t lock;
@@ -208,7 +192,7 @@ scc_enet_start_xmit(struct sk_buff *skb,
 		/* Ooops.  All transmit buffers are full.  Bail out.
 		 * This should not happen, since cep->tx_busy should be set.
 		 */
-		printk("%s: tx queue full!.\n", dev->name);
+		printk(KERN_ERR "%s: tx queue full!.\n", dev->name);
 		return 1;
 	}
 #endif
@@ -270,29 +254,135 @@ scc_enet_start_xmit(struct sk_buff *skb,
 	return 0;
 }
 
+/*
+ * Transmits up to 3 memory locations. This 3 locations must be cache-flushed
+ * before this function is invoked. The memory won't be freed after
+ * transmission. The function takes physical addresses!
+ */
+
+int scc_enet_multiple_xmit(struct net_device *dev,unsigned count, unsigned first,
+	unsigned first_len, unsigned second, unsigned second_len, unsigned third,
+	unsigned third_len)
+{
+	struct scc_enet_private *cep = (struct scc_enet_private *)dev->priv;
+	volatile cbd_t	*bdp,*first_bdp;
+	unsigned pad = 0;
+	int tmpcnt;
+
+	/* nothing to send ? */
+	if (!count)
+		return 0;
+
+	if (count>TX_RING_SIZE)
+		return 1;
+
+	spin_lock_irq(&cep->lock);
+
+	/* not enough free descriptors? */
+	bdp = cep->cur_tx;
+	tmpcnt = count;
+	do {
+		if (bdp->cbd_sc & BD_ENET_TX_READY) {
+			spin_unlock_irq(&cep->lock);
+			return 1;
+		}
+		if (bdp->cbd_sc & BD_ENET_TX_WRAP)
+			bdp = cep->tx_bd_base;
+		else
+			bdp++;
+
+	} while (--tmpcnt);
+
+	bdp = cep->cur_tx;
+	first_bdp = bdp;
+
+	if (first_len + second_len + third_len < ETH_ZLEN) {
+		pad = BD_ENET_TX_PAD;
+	}
+
+	/* setup first descriptor */
+
+	cep->tx_skbuff[cep->skb_cur] = NULL;
+	bdp->cbd_datlen = first_len;
+	bdp->cbd_bufaddr = first;
+	cep->skb_cur = (cep->skb_cur + 1) & TX_RING_MOD_MASK;
+
+	/* setup second descriptor */
+	if (count > 1) {
+		if (bdp->cbd_sc & BD_ENET_TX_WRAP) {
+			bdp = cep->tx_bd_base;
+		}
+		else {
+			bdp++;
+		}
+		cep->tx_skbuff[cep->skb_cur] = NULL;
+		bdp->cbd_datlen = second_len;
+		bdp->cbd_bufaddr = second;
+		cep->skb_cur = (cep->skb_cur + 1) & TX_RING_MOD_MASK;
+
+		if (count > 2) {
+			bdp->cbd_sc = (bdp->cbd_sc & BD_ENET_TX_WRAP) | BD_ENET_TX_READY;
+			if (bdp->cbd_sc & BD_ENET_TX_WRAP) {
+				bdp = cep->tx_bd_base;
+			}
+			else {
+				bdp++;
+			}
+			cep->tx_skbuff[cep->skb_cur] = NULL;
+			bdp->cbd_datlen = third_len;
+			bdp->cbd_bufaddr = third;
+			cep->skb_cur = (cep->skb_cur + 1) & TX_RING_MOD_MASK;
+		}
+	}
+	bdp->cbd_sc = (bdp->cbd_sc & BD_ENET_TX_WRAP) | BD_ENET_TX_READY |
+	BD_ENET_TX_INTR | BD_ENET_TX_LAST | BD_ENET_TX_TC | pad;
+	if (count > 1) {
+		first_bdp->cbd_sc = (first_bdp->cbd_sc & BD_ENET_TX_WRAP) | BD_ENET_TX_READY;
+	}
+
+	if (bdp->cbd_sc & BD_ENET_TX_WRAP) {
+		bdp = cep->tx_bd_base;
+	}
+	else {
+		bdp++;
+	}
+
+	if (bdp->cbd_sc & BD_ENET_TX_READY) {
+		netif_stop_queue(dev);
+		cep->tx_full = 1;
+	}
+
+	cep->cur_tx = (cbd_t *) bdp;
+
+	spin_unlock_irq(&cep->lock);
+
+	return 0;
+}
+EXPORT_SYMBOL(scc_enet_multiple_xmit);
+
 static void
 scc_enet_timeout(struct net_device *dev)
 {
 	struct scc_enet_private *cep = (struct scc_enet_private *)dev->priv;
 
-	printk("%s: transmit timed out.\n", dev->name);
+	printk(KERN_ERR "%s: transmit timed out.\n", dev->name);
 	cep->stats.tx_errors++;
 #ifndef final_version
 	{
 		int	i;
 		cbd_t	*bdp;
-		printk(" Ring data dump: cur_tx %p%s cur_rx %p.\n",
+		printk(KERN_DEBUG " Ring data dump: cur_tx %p%s cur_rx %p.\n",
 		       cep->cur_tx, cep->tx_full ? " (full)" : "",
 		       cep->cur_rx);
 		bdp = cep->tx_bd_base;
 		for (i = 0 ; i < TX_RING_SIZE; i++, bdp++)
-			printk("%04x %04x %08x\n",
+			printk(KERN_DEBUG "%04x %04x %08x\n",
 			       bdp->cbd_sc,
 			       bdp->cbd_datlen,
 			       bdp->cbd_bufaddr);
 		bdp = cep->rx_bd_base;
 		for (i = 0 ; i < RX_RING_SIZE; i++, bdp++)
-			printk("%04x %04x %08x\n",
+			printk(KERN_DEBUG "%04x %04x %08x\n",
 			       bdp->cbd_sc,
 			       bdp->cbd_datlen,
 			       bdp->cbd_bufaddr);
@@ -376,7 +466,8 @@ scc_enet_interrupt(void *dev_id, struct 
 
 		/* Free the sk buffer associated with this last transmit.
 		*/
-		dev_kfree_skb_irq(cep->tx_skbuff[cep->skb_dirty]);
+		if (cep->tx_skbuff[cep->skb_dirty])
+			dev_kfree_skb_irq(cep->tx_skbuff[cep->skb_dirty]);
 		cep->skb_dirty = (cep->skb_dirty + 1) & TX_RING_MOD_MASK;
 
 		/* Update pointer to next buffer descriptor to be transmitted.
@@ -446,8 +537,9 @@ scc_enet_rx(struct net_device *dev)
 {
 	struct	scc_enet_private *cep;
 	volatile cbd_t	*bdp;
-	struct	sk_buff *skb;
+	struct	sk_buff *skb,*rx_skb;
 	ushort	pkt_len;
+	ushort	skb_cur_rx;
 
 	cep = (struct scc_enet_private *)dev->priv;
 
@@ -455,6 +547,7 @@ scc_enet_rx(struct net_device *dev)
 	 * These get messed up if we get called due to a busy condition.
 	 */
 	bdp = cep->cur_rx;
+	skb_cur_rx = cep->skb_cur_rx;
 
 for (;;) {
 	if (bdp->cbd_sc & BD_ENET_RX_EMPTY)
@@ -466,7 +559,7 @@ for (;;) {
 	 */
 	if ((bdp->cbd_sc & (BD_ENET_RX_FIRST | BD_ENET_RX_LAST)) !=
 		(BD_ENET_RX_FIRST | BD_ENET_RX_LAST))
-			printk("CPM ENET: rcv is not first+last\n");
+			printk(KERN_CRIT "CPM ENET: rcv is not first+last\n");
 #endif
 
 	/* Frame too long or too short.
@@ -493,47 +586,53 @@ for (;;) {
 		*/
 		cep->stats.rx_packets++;
 		pkt_len = bdp->cbd_datlen;
-		cep->stats.rx_bytes += pkt_len;
+		cep->stats.rx_bytes += pkt_len - 4;
 
-		/* This does 16 byte alignment, much more than we need.
-		 * The packet length includes FCS, but we don't want to
-		 * include that when passing upstream as it messes up
-		 * bridging applications.
-		 */
-		skb = dev_alloc_skb(pkt_len-4);
+		/* Allocate a new skb
+		*/
 
-		if (skb == NULL) {
-			printk("%s: Memory squeeze, dropping packet.\n", dev->name);
-			cep->stats.rx_dropped++;
-		}
+		if ( (skb = dev_alloc_skb(PKT_MAXBLR_SIZE)) == NULL)
+		{
+			printk(KERN_ERR "%s: Memory squeeze, dropping packet.\n",dev->name);
+ 			cep->stats.rx_dropped++;
+ 		}
 		else {
-			skb->dev = dev;
-			skb_put(skb,pkt_len-4);	/* Make room */
-			eth_copy_and_sum(skb,
-				cep->rx_vaddr[bdp - cep->rx_bd_base],
-				pkt_len-4, 0);
-			skb->protocol=eth_type_trans(skb,dev);
-			netif_rx(skb);
+			/* swap new and filled skb
+			*/
+ 			skb->dev = dev;
+			/* invalidate data cache to prevent memory-modification in
+			 * write-back-mode and to get the real data on the next read
+			 */
+			invalidate_dcache_range((unsigned long) skb->data,(unsigned long) skb->data + PKT_MAXBLR_SIZE - 1);
+			rx_skb = cep->rx_skbuff[skb_cur_rx];
+			cep->rx_skbuff[skb_cur_rx] = skb;
+			bdp->cbd_bufaddr = __pa(skb->data);
+
+			/* Don't include FCS as it messes up bridging applications */
+			skb_put(rx_skb,pkt_len-4);
+			rx_skb->protocol=eth_type_trans(rx_skb,dev);
+			netif_rx(rx_skb);
 		}
 	}
 
-	/* Clear the status flags for this buffer.
-	*/
-	bdp->cbd_sc &= ~BD_ENET_RX_STATS;
-
-	/* Mark the buffer empty.
+	/* Clear the status flags for this buffer and mark the buffer empty.
 	*/
-	bdp->cbd_sc |= BD_ENET_RX_EMPTY;
+	bdp->cbd_sc = (bdp->cbd_sc & ~BD_ENET_RX_STATS) | BD_ENET_RX_EMPTY;
 
 	/* Update BD pointer to next entry.
 	*/
-	if (bdp->cbd_sc & BD_ENET_RX_WRAP)
+	if (bdp->cbd_sc & BD_ENET_RX_WRAP) {
 		bdp = cep->rx_bd_base;
-	else
+		skb_cur_rx = 0;
+	}
+	else {
 		bdp++;
+		skb_cur_rx++;
+	}
 
    }
 	cep->cur_rx = (cbd_t *)bdp;
+	cep->skb_cur_rx = skb_cur_rx;
 
 	return 0;
 }
@@ -581,7 +680,7 @@ static void set_multicast_list(struct ne
 	if (dev->flags&IFF_PROMISC) {
 	
 		/* Log any net taps. */
-		printk("%s: Promiscuous mode enabled.\n", dev->name);
+		printk(KERN_INFO "%s: Promiscuous mode enabled.\n", dev->name);
 		cep->sccp->scc_psmr |= SCC_PSMR_PRO;
 	} else {
 
@@ -644,10 +743,9 @@ static int __init scc_enet_init(void)
 {
 	struct net_device *dev;
 	struct scc_enet_private *cep;
-	int i, j, k, err;
+	int i, err;
 	uint dp_offset;
-	unsigned char	*eap, *ba;
-	dma_addr_t	mem_addr;
+	unsigned char	*eap;
 	bd_t		*bd;
 	volatile	cbd_t		*bdp;
 	volatile	cpm8xx_t	*cp;
@@ -758,6 +856,7 @@ static int __init scc_enet_init(void)
 
 	cep->dirty_tx = cep->cur_tx = cep->tx_bd_base;
 	cep->cur_rx = cep->rx_bd_base;
+	cep->skb_cur_rx = 0;
 
 	/* Issue init Rx BD command for SCC.
 	 * Manual says to perform an Init Rx parameters here.  We have
@@ -838,26 +937,21 @@ static int __init scc_enet_init(void)
 	bdp--;
 	bdp->cbd_sc |= BD_SC_WRAP;
 
-	bdp = cep->rx_bd_base;
-	k = 0;
-	for (i=0; i<CPM_ENET_RX_PAGES; i++) {
+	/* allocate skbs for receive-buffers */
 
-		/* Allocate a page.
-		*/
-		ba = (unsigned char *)dma_alloc_coherent(NULL, PAGE_SIZE,
-				&mem_addr, GFP_KERNEL);
-		/* BUG: no check for failure */
+	bdp = cep->rx_bd_base;
 
-		/* Initialize the BD for every fragment in the page.
-		*/
-		for (j=0; j<CPM_ENET_RX_FRPPG; j++) {
-			bdp->cbd_sc = BD_ENET_RX_EMPTY | BD_ENET_RX_INTR;
-			bdp->cbd_bufaddr = mem_addr;
-			cep->rx_vaddr[k++] = ba;
-			mem_addr += CPM_ENET_RX_FRSIZE;
-			ba += CPM_ENET_RX_FRSIZE;
-			bdp++;
-		}
+	for (i=0; i<RX_RING_SIZE; i++) {
+		cep->rx_skbuff[i] = dev_alloc_skb(PKT_MAXBLR_SIZE);
+		cep->rx_skbuff[i]->dev = dev;
+		/* invalidate data cache to prevent memory-modification in
+		 * write-back-mode and to get the real data on the next read.
+		 */
+		invalidate_dcache_range((unsigned long) cep->rx_skbuff[i]->data,
+			(unsigned long) cep->rx_skbuff[i]->data + PKT_MAXBLR_SIZE - 1);
+		bdp->cbd_sc = BD_ENET_RX_EMPTY | BD_ENET_RX_INTR;
+		bdp->cbd_bufaddr = __pa(cep->rx_skbuff[i]->data);
+		bdp++;
 	}
 
 	/* Set the last buffer to wrap.
@@ -995,7 +1089,7 @@ static int __init scc_enet_init(void)
 	*/
 	sccp->scc_gsmrl |= (SCC_GSMRL_ENR | SCC_GSMRL_ENT);
 
-	printk("%s: CPM ENET Version 0.2 on SCC%d, ", dev->name, SCC_ENET+1);
+	printk(KERN_INFO "%s: CPM ENET Version 0.2.dbox2 on SCC%d, ", dev->name, SCC_ENET+1);
 	for (i=0; i<5; i++)
 		printk("%02x:", dev->dev_addr[i]);
 	printk("%02x\n", dev->dev_addr[5]);
diff --git a/arch/ppc/Kconfig b/arch/ppc/Kconfig
index cc3f64c..9ec4c2a 100644
--- a/arch/ppc/Kconfig
+++ b/arch/ppc/Kconfig
@@ -504,6 +504,9 @@ config WINCEPT
 	  MPC821 PowerPC, introduced in 1998 and designed to be used in
 	  thin-client machines.  Say Y to support it directly.
 
+config DBOX2
+	bool "dbox2"
+
 endchoice
 
 choice
diff --git a/arch/ppc/platforms/Makefile b/arch/ppc/platforms/Makefile
index 7c5cdab..e987b9a 100644
--- a/arch/ppc/platforms/Makefile
+++ b/arch/ppc/platforms/Makefile
@@ -45,6 +45,7 @@ obj-$(CONFIG_SBC82xx)		+= sbc82xx.o
 obj-$(CONFIG_SPRUCE)		+= spruce.o
 obj-$(CONFIG_LITE5200)		+= lite5200.o
 obj-$(CONFIG_EV64360)		+= ev64360.o
+obj-$(CONFIG_DBOX2)			+= dbox2.o
 
 ifeq ($(CONFIG_SMP),y)
 obj-$(CONFIG_PPC_PMAC)		+= pmac_smp.o
diff --git a/arch/ppc/platforms/dbox2.c b/arch/ppc/platforms/dbox2.c
new file mode 100644
index 0000000..62fb7c5
--- /dev/null
+++ b/arch/ppc/platforms/dbox2.c
@@ -0,0 +1,220 @@
+/*
+ * arch/ppc/platforms/dbox2.c
+ *
+ * setup routines for the dbox2 board
+ *
+ * Copyright (C) 2004 Andreas Oberritter <obi@linuxtv.org>
+ *
+ */
+
+#include <linux/platform_device.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <asm/commproc.h>
+#include <asm/io.h>
+
+enum dbox2_mid {
+	MID_NOKIA	= 1,
+	MID_PHILIPS	= 2,
+	MID_SAGEM	= 3,
+};
+
+const char *manuf_name[3] = {
+	"Nokia",
+	"Philips",
+	"Sagem",
+};
+
+static unsigned int manuf_id;
+
+static struct resource enx_resources[] = {
+	[0] = {
+		.start	= 0x08000000,
+		.end	= 0x080033ff,
+		.flags	= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start	= 0x09000000,
+		.end	= 0x091fffff,
+		.flags	= IORESOURCE_MEM,
+	},
+	[2] = {
+		.start	= SIU_IRQ1,
+		.end	= SIU_IRQ1,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device enx_device = {
+	.name		= "enx",
+	.id		= 0,
+	.num_resources	= ARRAY_SIZE(enx_resources),
+	.resource	= enx_resources,
+};
+
+static struct resource gtx_resources[] = {
+	[0] = {
+		.start	= 0x08400000,
+		.end	= 0x08402fff,
+		.flags	= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start	= 0x08000000,
+		.end	= 0x081fffff,
+		.flags	= IORESOURCE_MEM,
+	},
+	[2] = {
+		.start	= SIU_IRQ1,
+		.end	= SIU_IRQ1,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device gtx_device = {
+	.name		= "gtx",
+	.id		= 0,
+	.num_resources	= ARRAY_SIZE(gtx_resources),
+	.resource	= gtx_resources,
+};
+
+static struct resource fp_resources[] = {
+	[0] = {
+		.start	= SIU_IRQ2,
+		.end	= SIU_IRQ2,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device fp_device = {
+	.name		= "fp",
+	.id		= 0,
+	.num_resources	= ARRAY_SIZE(fp_resources),
+	.resource	= fp_resources,
+};
+
+static struct resource fe_resources[] = {
+	[0] = {
+		.start	= SIU_IRQ7,
+		.end	= SIU_IRQ7,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device fe_device = {
+	.name		= "fe",
+	.id		= 0,
+	.num_resources	= ARRAY_SIZE(fe_resources),
+	.resource	= fe_resources,
+};
+
+static struct resource cam_resources[] = {
+	[0] = {
+		.start	= 0x0c000000,
+		.end	= 0x0c01ffff,
+		.flags	= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start	= SIU_IRQ3,
+		.end	= SIU_IRQ3,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device cam_device = {
+	.name		= "cam",
+	.id		= 0,
+	.num_resources	= ARRAY_SIZE(cam_resources),
+	.resource	= cam_resources,
+};
+
+static struct resource avia_resources[] = {
+	[0] = {
+		.start	= 0x0a000000,
+		.end	= 0x0a0001ff,
+		.flags	= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start	= SIU_IRQ4,
+		.end	= SIU_IRQ4,
+		.flags	= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device avia_device = {
+	.name		= "avia",
+	.id		= 0,
+	.num_resources	= ARRAY_SIZE(avia_resources),
+	.resource	= avia_resources,
+};
+
+static ssize_t dbox2_manufacturer_node(struct bus_type *bus, char *buf)
+{
+	return sprintf(buf, "%s\n", manuf_name[manuf_id - 1]);
+}
+static BUS_ATTR(manufacturer, S_IRUGO, dbox2_manufacturer_node, NULL);
+
+static ssize_t dbox2_mID_node(struct bus_type *bus, char *buf)
+{
+	return sprintf(buf, "%d\n", manuf_id);
+}
+static BUS_ATTR(mID, S_IRUGO, dbox2_mID_node, NULL);
+
+static struct bus_attribute *const platform_bus_attrs[] = {
+	&bus_attr_manufacturer,
+	&bus_attr_mID,
+	NULL
+};
+
+static struct platform_device *dbox2_devs[] __initdata = {
+	&enx_device,
+	&fp_device,
+	&fe_device,
+	&cam_device,
+	&avia_device,
+};
+
+static int __init dbox2_add_devices(void)
+{
+	u8 *config_area;
+	int i;
+
+	config_area = ioremap(0x1001ffe0, 0x20);
+	if (!config_area) {
+		printk(KERN_ERR "dbox2: could not map config area!\n");
+		return -EIO;
+	}
+	manuf_id = config_area[0];
+	iounmap(config_area);
+
+	if ((manuf_id < MID_NOKIA) || (manuf_id > MID_SAGEM)) {
+		printk(KERN_ERR "dbox2: invalid config area!\n");
+		return -EIO;
+	}
+
+	printk(KERN_INFO "dbox2: %s board detected.\n", manuf_name[manuf_id - 1]);
+
+	if (manuf_id == MID_NOKIA) {
+		dbox2_devs[0] = &gtx_device;
+	} else if (manuf_id == MID_PHILIPS) {
+		cam_resources[0].start += 0x40000;
+		cam_resources[0].end += 0x40000;
+	}
+	fe_device.dev.platform_data = (void*)manuf_id;
+	
+	for (i=0; platform_bus_attrs[i]; i++){
+		int ret = bus_create_file(&platform_bus_type, platform_bus_attrs[i]);
+		if (ret<0){
+			while (--i>=0){
+				bus_remove_file(&platform_bus_type, platform_bus_attrs[i]);
+			}
+			printk(KERN_ERR "dbox2: error creating platform bus attributes: errno: %d\n",ret);
+		}
+	}
+	
+	return platform_add_devices(dbox2_devs, ARRAY_SIZE(dbox2_devs));
+}
+
+void __init board_init(void)
+{
+	device_initcall(dbox2_add_devices);
+}
diff --git a/arch/ppc/platforms/dbox2.h b/arch/ppc/platforms/dbox2.h
new file mode 100644
index 0000000..170c2c3
--- /dev/null
+++ b/arch/ppc/platforms/dbox2.h
@@ -0,0 +1,29 @@
+/*
+ * arch/ppc/platforms/dbox2.h
+ *
+ * Copyright (c) 2001-2002 Florian Schirmer <jolt@tuxbox.org>
+ *
+ */
+
+#ifndef _PPC_PLATFORMS_DBOX2_H
+#define _PPC_PLATFORMS_DBOX2_H
+
+#include <asm/ppcboot.h>
+
+/* physical base address of IMMR area */
+#define IMAP_ADDR	0xFF000000
+/* mapped size of IMMR area */
+#define IMAP_SIZE	(64 * 1024)
+
+#define PA_ENET_RXD	((u16)0x0004)
+#define PA_ENET_TXD	((u16)0x0008)
+#define PA_ENET_RCLK	((u16)0x0200)
+#define PA_ENET_TCLK	((u16)0x0800)
+#define PC_ENET_TENA	((u16)0x0002)
+#define PC_ENET_CLSN	((u16)0x0040)
+#define PC_ENET_RENA	((u16)0x0080)
+
+#define SICR_ENET_MASK	((u32)0x0000ff00)
+#define SICR_ENET_CLKRT	((u32)0x00003d00)
+
+#endif /* _PPC_PLATFORMS_DBOX2_H */
diff --git a/drivers/mtd/maps/Kconfig b/drivers/mtd/maps/Kconfig
index b9b77cf..63ff475 100644
--- a/drivers/mtd/maps/Kconfig
+++ b/drivers/mtd/maps/Kconfig
@@ -639,5 +639,8 @@ config MTD_PLATRAM
 
 	  This selection automatically selects the map_ram driver.
 
-endmenu
+config MTD_DBOX2
+	tristate "Map driver for the dbox2"
+	depends on DBOX2
 
+endmenu
diff --git a/drivers/video/Kconfig b/drivers/video/Kconfig
index cc8e3bf..b21a9d5 100644
--- a/drivers/video/Kconfig
+++ b/drivers/video/Kconfig
@@ -335,6 +335,17 @@ config FB_OF
 	  Say Y if you want support with Open Firmware for your graphics
 	  board.
 
+config FB_DBOX2
+	bool "Framebuffer generic functions (for dbox2)"
+	depends on FB && PPC
+	select FB_CFB_FILLRECT
+	select FB_CFB_COPYAREA
+	select FB_CFB_IMAGEBLIT
+	select FB_SOFT_CURSOR
+	help
+	  Say Y here to include the generic functions necessary for
+	  building the (external) dbox2 driver
+
 config FB_CONTROL
 	bool "Apple \"control\" display support"
 	depends on (FB = y) && PPC_PMAC
diff --git a/include/asm-ppc/mpc8xx.h b/include/asm-ppc/mpc8xx.h
index 46f159c..aa670aa 100644
--- a/include/asm-ppc/mpc8xx.h
+++ b/include/asm-ppc/mpc8xx.h
@@ -32,6 +32,10 @@
 #include <platforms/rpxclassic.h>
 #endif
 
+#ifdef CONFIG_DBOX2
+#include <platforms/dbox2.h>
+#endif
+
 #if defined(CONFIG_TQM8xxL)
 #include <platforms/tqm8xx.h>
 #endif
diff --git a/include/asm-ppc/pgtable.h b/include/asm-ppc/pgtable.h
index 6d1c39e..5aa5028 100644
--- a/include/asm-ppc/pgtable.h
+++ b/include/asm-ppc/pgtable.h
@@ -768,11 +768,23 @@ extern void paging_init(void);
  * must not include the _PAGE_PRESENT bit, the _PAGE_FILE bit, or the
  *_PAGE_HASHPTE bit (if used).  -- paulus
  */
+#if (CONFIG_8xx)
+/* usually:
+   24 bits offset, 5 bits type, 3 bits flags 
+      so enough for 64 GiByte
+   as a quick and dirty workaround we reduce this to:
+   19 bits offset, 5 bits type, 8 bits flags
+      so enough for 2 GiByte
+*/
+#define __pte_to_swp_entry(pte)		((swp_entry_t) { pte_val(pte) >> 8 })
+#define __swp_entry_to_pte(x)		((pte_t) { (x).val << 8 })
+#else
+#define __pte_to_swp_entry(pte)		((swp_entry_t) { pte_val(pte) >> 3 })
+#define __swp_entry_to_pte(x)		((pte_t) { (x).val << 3 })
+#endif
 #define __swp_type(entry)		((entry).val & 0x1f)
 #define __swp_offset(entry)		((entry).val >> 5)
 #define __swp_entry(type, offset)	((swp_entry_t) { (type) | ((offset) << 5) })
-#define __pte_to_swp_entry(pte)		((swp_entry_t) { pte_val(pte) >> 3 })
-#define __swp_entry_to_pte(x)		((pte_t) { (x).val << 3 })
 
 /* Encode and decode a nonlinear file mapping entry */
 #define PTE_FILE_MAX_BITS	29
